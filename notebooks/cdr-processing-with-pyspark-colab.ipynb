{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_test",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoViotti/cdr-training/blob/development/notebooks/cdr-processing-with-pyspark-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx"
      },
      "source": [
        "\n",
        "# **CDR processing with Pyspark inÂ Colab**\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment. Follow the steps to install the dependencies:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz  \n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILheUROOhprv"
      },
      "source": [
        "Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1b8k_OVf2QF"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwrqMk3HiMiE"
      },
      "source": [
        "Run a local spark session to test your installation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Uz1NL4gHFx"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx"
      },
      "source": [
        "# Load data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAISFqHXf7dt"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNsM_jHqrjBg"
      },
      "source": [
        "Check the dataset is uploaded correctly in the system by the following command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m606eNuQgA82"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "A couple of tests to make sure it is working:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZeJ7WQCgM8g"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "dataset = spark.read.csv('BostonHousing.csv',inferSchema=True, header =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gok1FXWugYkE"
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKSqdT9QgkfD"
      },
      "source": [
        "#Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')\n",
        "\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "#Input vs Output\n",
        "finalized_data = output.select(\"Attributes\",\"medv\")\n",
        "\n",
        "finalized_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPIsEMK0suEp"
      },
      "source": [
        "# References:\r\n",
        "\r\n",
        "[https://colab.research.google.com/github/asifahmed90/pyspark-ML-in-Colab/blob/master/PySpark_Regression_Analysis.ipynb](https://colab.research.google.com/github/asifahmed90/pyspark-ML-in-Colab/blob/master/PySpark_Regression_Analysis.ipynb)"
      ]
    }
  ]
}